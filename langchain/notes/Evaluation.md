# Heuristic Evaluation & LLM as Judge

## 1. Heuristic Evaluation (휴리스틱 평가)

### **1.1 개요**

휴리스틱 평가는 전문가가 정해진 평가 기준(Heuristics)을 기반으로 시스템의 사용자 경험(UX) 및 기능적 품질을 평가하는 방법입니다. 이는 사용자의 행동 데이터를 수집하지 않고도 빠르게 문제를 식별하고 개선할 수 있는 강력한 방법론입니다.

### **1.2 평가 방법**

1. **평가 기준 정의**: UX 원칙(Nielsen의 10가지 휴리스틱), 기능적 요건 등을 기준으로 설정
2. **평가 수행**: 전문가들이 시스템을 사용하면서 문제점을 발견
3. **문제 분류 및 개선 방안 제시**: 심각도(S), 발생 빈도(F), 수정 난이도(D) 등을 고려하여 개선 우선순위 설정

### **1.3 Nielsen의 10가지 휴리스틱 원칙**

| #   | 휴리스틱 원칙                | 설명                                                 |
| --- | ---------------------------- | ---------------------------------------------------- |
| 1   | 시스템 상태 가시성           | 사용자에게 현재 상태를 명확하게 제공                 |
| 2   | 현실과의 일치                | 실제 사용자 언어와 개념을 반영                       |
| 3   | 사용자 통제 및 자유          | 사용자가 실수를 복구할 수 있도록 허용                |
| 4   | 일관성과 표준화              | 사용자가 익숙한 방식으로 인터페이스를 설계           |
| 5   | 오류 예방                    | 오류 발생 가능성을 최소화하는 설계                   |
| 6   | 인식보다는 회상              | 사용자가 정보를 기억하지 않아도 쉽게 탐색 가능       |
| 7   | 효율성과 유연성              | 초보자와 전문가 모두 편리하게 사용할 수 있도록 설계  |
| 8   | 미적 디자인 및 단순성        | 불필요한 정보를 줄여 가독성을 향상                   |
| 9   | 사용자가 오류를 진단 및 복구 | 오류 메시지를 명확하게 제공하여 문제 해결 지원       |
| 10  | 도움말 및 문서화             | 사용자가 필요할 때 쉽게 도움말을 찾을 수 있도록 제공 |

### **1.4 추가적인 평가 기법**

- **Cognitive Walkthrough (인지적 탐색법)**: 사용자가 특정 목표를 수행하는 과정에서 직면하는 문제를 분석하는 방법
- **Think-Aloud Protocol (생각을 말하면서 테스트)**: 사용자가 작업을 수행하면서 자신의 생각을 소리 내어 설명하게 하여 UX 문제를 파악
- **Comparative Usability Testing (비교 사용성 테스트)**: 여러 디자인을 비교하여 최적의 사용자 경험을 찾는 방식

---

## 2. LLM as Judge (LLM 기반 평가)

### **2.1 개요**

LLM(Large Language Model)을 평가자로 활용하는 방법론은 AI 모델을 이용하여 텍스트 생성 시스템, 검색 시스템 등의 품질을 평가하는 방식입니다. GPT-4, Claude, PaLM 등과 같은 대형 언어 모델이 인간 심사자의 역할을 대신할 수 있습니다.

### **2.2 평가 방식**

1. **LLM을 활용한 자동 평가**

   - 응답 품질 평가 (정확성, 유창성, 일관성 등)
   - 검색 결과의 적절성 평가
   - 생성된 텍스트의 의미적 유사성 판단

2. **LLM이 직접 심사하는 방법**
   - 모델이 평가 지표를 기준으로 응답을 비교 및 채점
   - 각 응답에 대한 점수 부여 및 피드백 생성

### **2.3 장점 및 단점**

#### **장점**

- 평가 자동화로 시간 및 비용 절감 가능
- 평가 기준을 일관되게 적용 가능
- 다양한 모델 및 데이터를 동시에 평가 가능

#### **단점**

- LLM의 평가가 완벽하지 않으며 편향(Bias)이 존재할 수 있음
- 특정 맥락에서 부정확한 평가를 할 가능성이 있음
- 인간의 직관적 판단과 비교했을 때 정교한 평가가 어려울 수 있음

---

## 3. 평가 기법 (General Evaluation Metrics)

### **3.1 임베딩 거리(Embedding Distance)**

- 문서와 쿼리 간의 벡터 거리를 계산하여 유사도를 평가하는 기법
- 대표적인 거리 계산 방식: **코사인 유사도(Cosine Similarity)**, **유클리디안 거리(Euclidean Distance)**

### **3.2 크로스 인코더(Cross Encoder) 기반 평가**

- 모델이 쿼리와 문서를 함께 입력받아, 직접 관계를 학습하여 평가 점수를 출력하는 방식
- 쿼리와 문서를 각각 독립적으로 벡터화하는 **Bi-Encoder 방식**보다 더 정확하지만, 연산 비용이 높음

### **3.3 ROUGE Metrics**

- 생성된 텍스트의 유사성을 평가하는 대표적인 지표
- 대표적인 유형:
  - **ROUGE-1**: 단어 단위 일치율 평가
  - **ROUGE-2**: 2-gram 단위 평가
  - **ROUGE-L**: 문장의 장기적 구조(LCS, Longest Common Subsequence) 평가

### **3.4 LangChain 기반 평가 기법**

#### **3.4.1 LangChain - QA Evaluation**

LangChain을 활용하여 QA 시스템을 평가하는 방법으로, 모델의 답변이 원본 문서와 얼마나 일치하는지를 측정할 수 있음.

#### **3.4.2 Criteria Evaluation (No Labels)**

- 사전 정의된 기준 없이 모델이 응답의 품질을 평가하는 방식
- 모델이 응답의 정확성, 유창성 등을 자체 판단하여 평가 점수를 부여

#### **3.4.3 Criteria Evaluation (With Labels)**

- 특정 기준(예: 정확성, 일관성, 창의성 등)에 따라 응답을 평가하는 방법
- 사람이 사전 정의한 라벨(정확/부정확, 논리적/비논리적 등)을 기준으로 LLM이 평가를 수행

---

## 4. Heuristic Evaluation vs. LLM as Judge 비교

| 평가 방법                | 평가 방식             | 장점                        | 단점                                        |
| ------------------------ | --------------------- | --------------------------- | ------------------------------------------- |
| **Heuristic Evaluation** | 전문가 평가 기준 적용 | 빠른 문제 식별, 체계적 분석 | 주관성 높음, 실제 사용자와 차이 발생 가능   |
| **LLM as Judge**         | AI가 자동 평가 수행   | 비용 절감, 일관된 평가      | 편향 가능성, 특정 맥락에서 부정확할 수 있음 |

---

이 문서는 **Heuristic Evaluation**, **LLM as Judge**, 그리고 **일반적인 평가 기법(Embedding Distance, Cross Encoder, ROUGE 등)**을 포함하여 다양한 평가 방식을 정리하였습니다. 각 평가 방법은 도메인과 목표에 따라 선택적으로 활용될 수 있습니다.
