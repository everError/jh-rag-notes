{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a898547",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e15f76c",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6d77f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0800c924",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bca641c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f18fd5f",
   "metadata": {},
   "source": [
    "`(3) 벡터저장소 로드`  \n",
    "- 저장해 둔 크로마 벡터저장소를 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0562285f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터 저장소에 저장된 문서 수: 11\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "#이미 Chroma db가 존재한다면 생성당시와 동일한 모델 선택\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\", \n",
    ")\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"chroma_test\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    )\n",
    "\n",
    "print(f\"벡터 저장소에 저장된 문서 수: {vectorstore._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee0237e",
   "metadata": {},
   "source": [
    "## 2. LangChain LCEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26db4266",
   "metadata": {},
   "source": [
    "### 2.1 Prompt + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6650c629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['query'] messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], template='{query}'))]\n"
     ]
    }
   ],
   "source": [
    "# 다중 메시지 전송\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 모델 초기화\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\", \n",
    "    temperature=0.3, \n",
    "    max_tokens=100,\n",
    "    )\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant.\"), # system 메시지 - 역할부여 \n",
    "    (\"user\", \"{query}\"), # user - 외부에서 전달받는 사용자의 질문을 지정\n",
    "]\n",
    "\n",
    "# 메시지 리스트를 템플릿으로 변환\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "# 템플릿을 출력\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff39eda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['query']\n"
     ]
    }
   ],
   "source": [
    "# 템플릿 입력 변수를 출력\n",
    "print(prompt.input_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "771e1e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are a helpful assistant.\n",
      "Human: 테슬라 창업자는 누구인가요?\n"
     ]
    }
   ],
   "source": [
    "# input 값을 전달하여 프롬프트를 렌더링\n",
    "# format method로 사전에 정의해둔 query 위치로 질문 바인딩\n",
    "prompt_text = prompt.format(query=\"테슬라 창업자는 누구인가요?\")\n",
    "\n",
    "print(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f0e9bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)이라는 두 명의 엔지니어에 의해 설립되었습니다. 엘론 머스크는 2004년에 테슬라의 초기 투자자로 참여한 후, 이후 CEO로서 회사를 이끌게 되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 모델에 prompt text를 직접 입력\n",
    "response = llm.invoke(prompt_text)\n",
    "\n",
    "# 모델의 응답을 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27045656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['query'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], template='{query}'))]) last=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001CAD8DE5690>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001CADA499810>, root_client=<openai.OpenAI object at 0x000001CABF87BE50>, root_async_client=<openai.AsyncOpenAI object at 0x000001CADA50D890>, model_name='gpt-4o-mini', temperature=0.3, openai_api_key=SecretStr('**********'), openai_proxy='', max_tokens=100)\n"
     ]
    }
   ],
   "source": [
    "# LCEL 체인을 구성 pipe 연산자로 prompt와 llm을 연결 -> chain을 구성\n",
    "chain = prompt | llm\n",
    "\n",
    "# 체인을 출력\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a65c9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'properties': {'query': {'title': 'Query', 'type': 'string'}},\n",
      " 'required': ['query'],\n",
      " 'title': 'PromptInput',\n",
      " 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "# 체인의 입력 스키마를 출력\n",
    "from pprint import pprint\n",
    "pprint(chain.input_schema.schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b371cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타르펋(Mark Tarpenning)에 의해 설립되었습니다. 엘론 머스크는 2004년에 테슬라에 투자하고 이후 CEO로 취임하면서 회사의 성장에 큰 영향을 미쳤습니다. 따라서 엘론 머스크는 테슬라\n"
     ]
    }
   ],
   "source": [
    "# 체인을 실행 - 옵션 1\n",
    "response = chain.invoke({\"query\":\"테슬라 창업자는 누구인가요?\"})\n",
    "\n",
    "# 체인의 응답을 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68e91772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 설립되었습니다. 이후 엘론 머스크가 2004년에 투자자로 참여하면서 CEO로 취임하고 회사의 방향성을 크게 이끌어왔습니다. 따라서 엘론 머스크는 테슬라의 가장\n"
     ]
    }
   ],
   "source": [
    "# 체인을 실행 - 옵션 2 - 전달할 파라미터가 1개일 경우\n",
    "response = chain.invoke(\"테슬라 창업자는 누구인가요?\")\n",
    "\n",
    "# 체인의 응답을 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9e0da4",
   "metadata": {},
   "source": [
    "### 2.2 Prompt + LLM + Output Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80ac6ea",
   "metadata": {},
   "source": [
    "`a) 문자열 파싱 - StrOutputParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8de35b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 설립되었습니다. 이후 엘론 머스크가 2004년에 투자자로 참여하면서 CEO로 취임하고 회사의 방향성을 크게 이끌어왔습니다. 따라서 엘론 머스크는 테슬라의 가장', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 27, 'total_tokens': 127, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_39a40c96a0', 'finish_reason': 'length', 'logprobs': None}, id='run-11bef040-0ec0-4bf2-b8fc-056bbe7effb7-0', usage_metadata={'input_tokens': 27, 'output_tokens': 100, 'total_tokens': 127})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1a73a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 설립되었습니다. 이후 엘론 머스크가 2004년에 투자자로 참여하면서 CEO로 취임하고 회사의 방향성을 크게 이끌어왔습니다. 따라서 엘론 머스크는 테슬라의 가장'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# StrOutputParser - 문자열 출력을 파싱\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 출력 파서를 생성\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 출력 파서를 실행\n",
    "output_parser.invoke(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2ab22fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리비안(Rivian)은 2009년에 설립되었습니다. 이 회사는 전기차를 개발하고 제조하는 기업으로, 특히 전기 픽업트럭과 SUV 모델에 주력하고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "str_chain = prompt | llm  | output_parser\n",
    "\n",
    "query = \"리비안의 설립년도는 언제인가요?\"\n",
    "str_response = str_chain.invoke(query)\n",
    "\n",
    "print(str_response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea86ac6",
   "metadata": {},
   "source": [
    "`b) JSON 출력 - JsonOutputParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea62a751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```json\\n{\\n  \"창업자\": \"엘론 머스크\",\\n  \"설명\": \"엘론 머스크는 테슬라의 공동 창립자이자 CEO로, 전기차 및 지속 가능한 에너지 솔루션을 개발하는 데 기여하였습니다.\"\\n}\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 34, 'total_tokens': 96, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'stop', 'logprobs': None} id='run-392e9480-2003-4339-91d2-599fd8134bd7-0' usage_metadata={'input_tokens': 34, 'output_tokens': 62, 'total_tokens': 96}\n",
      "{'창업자': '엘론 머스크', '설명': '엘론 머스크는 테슬라의 공동 창립자이자 CEO로, 전기차 및 지속 가능한 에너지 솔루션을 개발하는 데 기여하였습니다.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# 출력 파서를 생성\n",
    "json_parser = JsonOutputParser()\n",
    "\n",
    "# 체인을 실행 (JSON 출력)\n",
    "json_response = chain.invoke(\"테슬라 창업자는 누구인가요? JSON 형식으로 출력해주세요.\") \n",
    "print(json_response)\n",
    "\n",
    "# 출력 파서를 실행\n",
    "json_parser_output = json_parser.invoke(json_response)\n",
    "print(json_parser_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6809cf4f",
   "metadata": {},
   "source": [
    "`c) Schema 지정 - PydanticOutputParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3ec0943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "PydanticOutputParser 프롬프트\n",
      "----------------------------------------\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Information about a person.\", \"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"The name of the person\", \"type\": \"string\"}, \"title\": {\"title\": \"Title\", \"description\": \"The title or position of the person.\", \"type\": \"string\"}}, \"required\": [\"name\", \"title\"]}\n",
      "```\n",
      "========================================\n",
      "Prompt 템플릿\n",
      "----------------------------------------\n",
      "System: Answer the user query. Wrap the output in `json` tags\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Information about a person.\", \"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"The name of the person\", \"type\": \"string\"}, \"title\": {\"title\": \"Title\", \"description\": \"The title or position of the person.\", \"type\": \"string\"}}, \"required\": [\"name\", \"title\"]}\n",
      "```\n",
      "Human: 테슬라 창업자는 누구인가요?\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "\n",
    "# Pydantic 모델을 생성\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"   #필수 - 모델(이 담는 정보)에 대한 설명\n",
    "#속성 정의 description 필수\n",
    "    name: str = Field(..., description=\"The name of the person\")\n",
    "    title: str = Field(..., description=\"The title or position of the person.\")\n",
    "\n",
    "# 출력 파서를 생성\n",
    "person_parser = PydanticOutputParser(pydantic_object=Person)\n",
    "print(\"========================================\")\n",
    "print(\"PydanticOutputParser 프롬프트\")\n",
    "print(\"----------------------------------------\")\n",
    "print(person_parser.get_format_instructions())\n",
    "print(\"========================================\")\n",
    "\n",
    "\n",
    "# Prompt 템플릿을 생성 - Pydantic 모델을 사용\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\",\n",
    "        ),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ").partial(format_instructions=person_parser.get_format_instructions())\n",
    "#정의한 모델에 대한 정보를 프롬프트 내에 직접 전달하기 위해 format instructions 메소드 사용\n",
    "\n",
    "print(\"Prompt 템플릿\")\n",
    "print(\"----------------------------------------\")\n",
    "print(prompt.format(query=\"테슬라 창업자는 누구인가요?\"))\n",
    "print(\"========================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b8a57e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='엘론 머스크', title='CEO 및 공동 창립자')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 체인을 구성\n",
    "person_chain = prompt | llm | person_parser\n",
    "\n",
    "# 체인을 실행\n",
    "response = person_chain.invoke(\"테슬라 창업자는 누구인가요?\")\n",
    "\n",
    "# 체인의 응답을 출력\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aae49f4",
   "metadata": {},
   "source": [
    "## 3. Chat Completion Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9198b73",
   "metadata": {},
   "source": [
    "`(1) stream`  \n",
    "- 입력에 대한 응답을 실시간 스트림을 생성하여 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b87c23a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하르드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 설립되었습니다. 엘론 머스크는 2004년에 투자자로 참여한 후 CEO로 취임하며 회사의 성장에 중요한 역할을 하게 되었습니다. 이후 그는 테슬라의 비전과 방향"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "for chunk in llm.stream(\"테슬라 창업자는 누구인가요?\"):\n",
    "    # 기본적으로 print 함수는 출력을 할 때마다 줄바꿈을 하지만, 줄바꿈 없이 출력하려면 end=\"\"를 사용하면 됩니다.\n",
    "    # flush=True 옵션을 사용하여 출력 버퍼를 즉시 비웁니다. 데이터를 지연 없이 즉시 출력하는 데 유용합니다.\n",
    "    print(chunk.content, end=\"\", flush=True)  \n",
    "    time.sleep(0.1)  # 0.1초 대기 (100ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b01677",
   "metadata": {},
   "source": [
    "`(2) batch`  \n",
    "- 입력 리스트에 대한 응답을 배치 단위로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1477bfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "테슬라의 창립자는 엘론 머스크(Elon Musk), 마틴 에버하드(Martin Eberhard), 마크 타페닝(Mark Tarpenning), 제프 스프링어(Jeffrey B. Straubel) 등 여러 명이 있습니다. 그러나 엘론 머스크는 2004년에 투자자로 참여한 후 CEO로서 회사의 방향성을 이끌어온 인물로 가장 잘 알려져 있습니다. 테슬라는\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "리비안(Rivian)의 창업자는 RJ 스카링(RJ Scaringe)입니다. 그는 2009년에 리비안을 설립하였으며, 전기차 제조업체로서 주로 전기 픽업트럭과 SUV를 개발하고 있습니다. RJ 스카링은 MIT에서 박사 학위를 받았으며, 지속 가능한 운송 수단에 대한 비전을 가지고 회사를 이끌고 있습니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"테슬라의 창업자는 누구인가요?\",\n",
    "    \"리비안의 창업자는 누구인가요?\",\n",
    "]\n",
    "\n",
    "responses = llm.batch(questions)\n",
    "\n",
    "for response in responses:\n",
    "    response.pretty_print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc16413",
   "metadata": {},
   "source": [
    "## 4. Runnable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a734f412",
   "metadata": {},
   "source": [
    "`(1) RunnableParallel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f21024b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 '\n",
      " '마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다. '\n",
      " '머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 '\n",
      " '이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다.')\n"
     ]
    }
   ],
   "source": [
    "# 문서 검색기 생성\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={'k': 1}, \n",
    ")\n",
    "\n",
    "query = \"테슬라 창업자는 누구인가요?\"\n",
    "retrieved_docs = retriever.invoke(query) # 사용자 입력과 유사한 1개의 단일 문서를 list 형태로 return\n",
    "\n",
    "retrieved_docs_text = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "pprint(retrieved_docs_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcbc4d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': '테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다. 머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다.',\n",
       " 'question': '테슬라 창업자는 누구인가요?'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "from operator import itemgetter\n",
    "\n",
    "# RunnableParrellel 구성\n",
    "runnable = RunnableParallel(\n",
    "    {\"context\": itemgetter(\"context\") , \"question\": itemgetter(\"question\")}\n",
    ")\n",
    "\n",
    "# 객체를 실행\n",
    "response = runnable.invoke({\"context\": retrieved_docs_text, \"question\": query})\n",
    "\n",
    "# 응답을 출력\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbeb7d0",
   "metadata": {},
   "source": [
    "`(2) RunnablePassthrough`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b6495f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': {'query': '테슬라 창업자는 누구인가요?'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "runnable = RunnableParallel(    #Dictionary 형태 출력\n",
    "    question=RunnablePassthrough(), #입력을 `그대로`` 전달\n",
    ")\n",
    "\n",
    "runnable.invoke({\"query\":\"테슬라 창업자는 누구인가요?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458adb6e",
   "metadata": {},
   "source": [
    "`(3) RunnableLambda`\n",
    "- 정의: 파이썬의 커스텀 함수를 매핑하는데 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "509b3f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '테슬라 창업자는 누구인가요?', 'word_count': 3}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def count_num_words(text):\n",
    "    return len(text.split())    #공백 기준으로 분할\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    question=RunnablePassthrough(),\n",
    "    word_count=RunnableLambda(count_num_words), #함수를 매핑\n",
    ")\n",
    "\n",
    "runnable.invoke(\"테슬라 창업자는 누구인가요?\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d7177b",
   "metadata": {},
   "source": [
    "## 5. 전체 RAG 파이프라인 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a953ff",
   "metadata": {},
   "source": [
    "`(1) RAG 프롬프트 템플릿`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c9b52c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Answer the question based only on the following context.\n",
      "Do not use any external information or knowledge. \n",
      "If the answer is not in the context, answer \"잘 모르겠습니다.\".\n",
      "\n",
      "[Context]\n",
      "\u001b[33;1m\u001b[1;3m{context}\u001b[0m\n",
      "\n",
      "[Question] \n",
      "\u001b[33;1m\u001b[1;3m{question}\u001b[0m\n",
      "\n",
      "[Answer]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt 템플릿을 생성\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context.\n",
    "Do not use any external information or knowledge. \n",
    "If the answer is not in the context, answer \"잘 모르겠습니다.\".\n",
    "\n",
    "[Context]\n",
    "{context}\n",
    "\n",
    "[Question] \n",
    "{question}\n",
    "\n",
    "[Answer]\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# 템플릿을 출력\n",
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03131d4a",
   "metadata": {},
   "source": [
    "`(2) Retriever Chain 연결`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09b7abf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 '\n",
      " '마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다. '\n",
      " '머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 '\n",
      " '이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다.\\n'\n",
      " '\\n'\n",
      " '테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 '\n",
      " '마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다. '\n",
      " '머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 '\n",
      " '이름을 따서 지어졌습니다. 테슬라는 2010')\n"
     ]
    }
   ],
   "source": [
    "# 벡터 검색기\n",
    "retriever = vectorstore.as_retriever(search_kwargs={'k': 2}) #2개의 문서 검색\n",
    "\n",
    "# 문서 포맷터 함수\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs]) #검색된 문서들을 하나의 문자열로 결합\n",
    "\n",
    "# 체인 구성\n",
    "retriever_chain = retriever | format_docs\n",
    "\n",
    "# 체인을 실행\n",
    "response = retriever_chain.invoke(\"테슬라 창업자는 누구인가요?\")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6957eeab",
   "metadata": {},
   "source": [
    "`(3) RAG Chain 연결`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d12f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# LLM 모델 생성\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, max_tokens=100)\n",
    "\n",
    "# 체인 생성\n",
    "rag_chain = (\n",
    "    {\"context\": retriever_chain , \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 체인 실행\n",
    "query = \"테슬라 창업자는 누구인가요?\"\n",
    "response = rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2b7fc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'마틴 에버하드와 마크 타페닝입니다.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 출력\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceb9f42",
   "metadata": {},
   "source": [
    "## 6. Gradio 챗봇"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57035b9",
   "metadata": {},
   "source": [
    "`(1) invoke 실행` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b207180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-env-piYnTqFT-py3.11\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-env-piYnTqFT-py3.11\\Lib\\site-packages\\gradio\\analytics.py:106: UserWarning: IMPORTANT: You are using gradio version 4.44.0, however version 4.44.1 is available, please upgrade. \n",
      "--------\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def answer_invoke(message, history):\n",
    "    response = rag_chain.invoke(message)\n",
    "    return response\n",
    "\n",
    "# Graiio 인터페이스 생성 \n",
    "demo = gr.ChatInterface(fn=answer_invoke, title=\"QA Bot\")\n",
    "\n",
    "# Graiio 실행  \n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82f7a6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "# Graiio 종료\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f970ba",
   "metadata": {},
   "source": [
    "`(2) stream 실행` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40b11b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-env-piYnTqFT-py3.11\\Lib\\site-packages\\gradio\\analytics.py:106: UserWarning: IMPORTANT: You are using gradio version 4.44.0, however version 4.44.1 is available, please upgrade. \n",
      "--------\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def answer_invoke(message, history):\n",
    "    partial_message = \"\"\n",
    "    for chunk in rag_chain.stream(message):         #토큰 단위로 출력\n",
    "        if chunk is not None:\n",
    "            partial_message = partial_message + chunk\n",
    "            time.sleep(0.1)\n",
    "            yield partial_message\n",
    "\n",
    "# Graiio 인터페이스 생성 \n",
    "demo = gr.ChatInterface(fn=answer_invoke, title=\"QA Bot\")\n",
    "\n",
    "# Graiio 실행  \n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be3f36e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "# Graiio 종료\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90ddd92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env-piYnTqFT-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
